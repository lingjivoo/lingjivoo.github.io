[ { "title": "Energybasedmodel Diffusionmodel", "url": "/posts/EnergyBasedModel-DiffusionModel/", "categories": "", "tags": "", "date": "2024-02-07 00:00:00 +0800", "snippet": "title: Energy Based Model &amp;amp; Diffusion Modelauthor: Cheng Luodate: 2024-02-07 13:34:00 +1100categories: [Study]tags: [Technique]pin: truemath: true—" }, { "title": "Neural Network Visualization", "url": "/posts/convolution-vis/", "categories": "Study", "tags": "Technique", "date": "2024-02-01 08:49:00 +0800", "snippet": "A great visualization toolAn Interactive Node-Link Visualization of Convolutional Neural Networks" }, { "title": "Essay-2024-01-17", "url": "/posts/Essay/", "categories": "Essay", "tags": "Mood", "date": "2024-01-17 18:45:00 +0800", "snippet": "2024年1月17日又是工作到很晚的一天。晚上总是会想很多事情每天追很多最新的论文充斥着浮躁与功利越来越像军备竞赛做点自己想做的事情却发现成本太大数据集收集了好几个月新做的方向前途未卜明明暗暗 摇摇曳曳做一点自己喜欢的 未知的科研 付出的代价太大朋友圈又陆陆续续有同辈的论文被接收了想想今年花了很大的精力与代价做未知又不笃定的事情每时每刻都会被动摇或者是为了一点执念吧黑暗中前行" }, { "title": "Cuda Programming", "url": "/posts/Cuda-Programming/", "categories": "Study", "tags": "Technique", "date": "2024-01-13 16:40:00 +0800", "snippet": "##Core Concepts: Host: CPU and its memory Device: GPU and its memory##Procedures Allocate the memory of host and initialize the data Allocate the memory of device and copy data from host to device Use the kernal functions of CUDA and complete computations on device Copy computed results from device to host Free the memory on both host and device** using the CUDA kernal functions to execute parallel computingglobal declares kernal«&amp;lt;grid, block»&amp;gt; defines the number of executing threadsEach thread has a thread ID (threadIdx)" }, { "title": "Softmax Temperature", "url": "/posts/Softmax-Temperature-vis/", "categories": "Study", "tags": "Technique", "date": "2024-01-12 16:30:00 +0800", "snippet": "Copied from Softmax TemperatureTemperature is a hyperparameter of LSTMs (and neural networks generally) used to control the randomness of predictions by scaling the logits before applying softmax. Temperature scaling has been widely used to improve performance for NLP tasks that utilize the Softmax decision layer.For explaining its utility, we will consider the case of Natural Language Generation, wherein we need to generate text by sampling out novel sequences from the language model (using the decoder part of the seq-to-seq architecture). At each time step in the decoding phase, we need to predict a token, which is done by sampling from a softmax distribution (over the vocabulary) using one of the sampling techniques. In short, once the logits are obtained, the quality and the diversity of the predictions is controlled by the softmax distribution and the sampling technique applied thereupon. This article is about tweaking the softmax distribution to control how diverse and novel the predictions are. The latter will be covered in a future article.Fig 1 is a snapshot of how the prediction is made at one of the intermediate timesteps in the decoding phase.But what is the issue here?The generated sequence will have a predictable and generic structure. And the reason is less entropy or randomness in the softmax distribution, in the sense that the likelihood of a particular word (corresponding to index 9 in the above example) getting chosen is way higher than the other words. A sequence being predictable is not problematic as long as the aim is to get realistic sequences. But if the goal is to generate a novel text or an image which has never been seen before, randomness is the holy grail.The Solution?Increase the randomness.And that’s precisely what Temperature scaling does. It characterizes the entropy of the probability distribution used for sampling, in other words, it controls how surprising or predictable the next word will be. The scaling is done by dividing the logit vector by a value T, which denotes the temperature, followed by the application of softmax.The effect of this scaling can be visualized in Fig 3:The distribution above approaches uniform distribution giving each word an equal probability of getting sampled out, thereby rendering a more creative look to the generated sequence. Too much creativity isn’t good either. In the extreme case, the generated text might not make sense at all. Hence, like all other hyperparameters, this needs to be tuned as well.ConclusionThe scale of temperature controls the smoothness of the output distribution. It, therefore, increases the sensitivity to low-probability candidates. As \\(T \\rightarrow \\infty\\), the distribution becomes more uniform, thus increasing the uncertainty. Contrarily, when \\(T \\rightarrow 0\\), the distribution collapses to a point mass.As mentioned earlier, the scope of Temperature Scaling is not limited to NLG. It is also used to calibrate deep learning models while training and in Reinforcement Learning as well. Another broader concept that it is a part of is Knowledge Distillation. Below are the links on these topics for further exploration.Author: Harshit Sharma Source" }, { "title": "3D Gaussian Splatting", "url": "/posts/3D-Gaussian-Splatting/", "categories": "Study", "tags": "Technique", "date": "2024-01-11 12:46:00 +0800", "snippet": "Code3D Gaussian SplattingClone the githubgit clone https://github.com/graphdeco-inria/gaussian-splatting --recursiveSetupconda env create --file environment.ymlconda activate gaussian_splattingNotesTheu cuda version must $\\geq 11.8$And then you need to install submodulespip install -q gaussian-splatting/submodules/diff-gaussian-rasterizationpip install -q /content/gaussian-splatting/submodules/simple-knnDatasetwget https://huggingface.co/camenduru/gaussian-splatting/resolve/main/tandt_db.zipunzip tandt_db.zipTrainpython train.py -s gaussian-splatting/tandt/trainEvalpython render.py -m &amp;lt;path to trained model&amp;gt; python render.py -m &amp;lt;path to pre-trained model&amp;gt; -s &amp;lt;path to COLMAP dataset&amp;gt;python metrics.py -m &amp;lt;path to pre-trained model&amp;gt;&amp;lt;path to trained model&amp;gt; may be outputs/xxxxCode ExplanationTrain.pymodel: GaussianModel (variable: gaussians)dataset: Scene (variable: scene)render: render (function: render, defined in gaussian_renderer) bg_color = [1, 1, 1] if dataset.white_background else [0, 0, 0] background = torch.tensor(bg_color, dtype=torch.float32, device=&quot;cuda&quot;) viewpoint_stack = None # Every 1000 its we increase the levels of SH up to a maximum degree if iteration % 1000 == 0: gaussians.oneupSHdegree() render_pkg = render(viewpoint_cam, gaussians, pipe, bg)Training: gaussians.update_learning_rate(iteration) # adjust the learning rate viewpoint_cam = viewpoint_stack.pop(randint(0, len(viewpoint_stack)-1)) # pick a random camera bg = torch.rand((3), device=&quot;cuda&quot;) if opt.random_background else background # set the background color render_pkg = render(viewpoint_cam, gaussians, pipe, bg) # render process image, viewspace_point_tensor, visibility_filter, radii = render_pkg[&quot;render&quot;], render_pkg[&quot;viewspace_points&quot;], render_pkg[&quot;visibility_filter&quot;], render_pkg[&quot;radii&quot;] # get rendered outputs loss = (1.0 - opt.lambda_dssim) * Ll1 + opt.lambda_dssim * (1.0 - ssim(image, gt_image)) # loss (reconstruction loss + ssim loss) The directional appearance component (color) of the radiance field is represented via spherical harmonics (SH)Spherical harmonic lighting (SH coefficients) # Every 1000 its we increase the levels of SH up to a maximum degree if iteration % 1000 == 0: gaussians.oneupSHdegree()Densification: # Densification if iteration &amp;lt; opt.densify_until_iter: # Keep track of max radii in image-space for pruning gaussians.max_radii2D[visibility_filter] = torch.max(gaussians.max_radii2D[visibility_filter], radii[visibility_filter]) gaussians.add_densification_stats(viewspace_point_tensor, visibility_filter) if iteration &amp;gt; opt.densify_from_iter and iteration % opt.densification_interval == 0: size_threshold = 20 if iteration &amp;gt; opt.opacity_reset_interval else None gaussians.densify_and_prune(opt.densify_grad_threshold, 0.005, scene.cameras_extent, size_threshold) if iteration % opt.opacity_reset_interval == 0 or (dataset.white_background and iteration == opt.densify_from_iter): gaussians.reset_opacity()ModelArguments self._xyz, # spatial position self._features_dc, self._features_rest, self._scaling, # scaling of ellipsoids self._rotation, # rotation of ellipsoids self._opacity, # opacity self.max_radii2D, self.xyz_gradient_accum self.denomCrucial funstions: # s: scaling matrix, r: rotation matrix def build_scaling_rotation(s, r): L = torch.zeros((s.shape[0], 3, 3), dtype=torch.float, device=&quot;cuda&quot;) R = build_rotation(r) L[:,0,0] = s[:,0] L[:,1,1] = s[:,1] L[:,2,2] = s[:,2] # L: 3x3, R: 3x3 L = R @ L return L def build_covariance_from_scaling_rotation(scaling, scaling_modifier, rotation): L = build_scaling_rotation(scaling_modifier * scaling, rotation) # actual_covariance = L @ L.transpose(1, 2) symm = strip_symmetric(actual_covariance) 3x3 -&amp;gt; 6 return symmActual_covariance is the symmetric matrix so that we get the upper right part. # get the upper triangular matrix def strip_lowerdiag(L): uncertainty = torch.zeros((L.shape[0], 6), dtype=torch.float, device=&quot;cuda&quot;) uncertainty[:, 0] = L[:, 0, 0] uncertainty[:, 1] = L[:, 0, 1] uncertainty[:, 2] = L[:, 0, 2] uncertainty[:, 3] = L[:, 1, 1] uncertainty[:, 4] = L[:, 1, 2] uncertainty[:, 5] = L[:, 2, 2] return uncertainty def strip_symmetric(sym): return strip_lowerdiag(sym)Scaling_matrix: A quaternion q to represent rotationq with real part $q_r$ and imaginary parts $q_i, q_j, and q_K$ to a rotation matrix R: def build_rotation(r): norm = torch.sqrt(r[:,0]*r[:,0] + r[:,1]*r[:,1] + r[:,2]*r[:,2] + r[:,3]*r[:,3]) q = r / norm[:, None] R = torch.zeros((q.size(0), 3, 3), device=&#39;cuda&#39;) r = q[:, 0] x = q[:, 1] y = q[:, 2] z = q[:, 3] R[:, 0, 0] = 1 - 2 * (y*y + z*z) R[:, 0, 1] = 2 * (x*y - r*z) R[:, 0, 2] = 2 * (x*z + r*y) R[:, 1, 0] = 2 * (x*y + r*z) R[:, 1, 1] = 1 - 2 * (x*x + z*z) R[:, 1, 2] = 2 * (y*z - r*x) R[:, 2, 0] = 2 * (x*z - r*y) R[:, 2, 1] = 2 * (y*z + r*x) R[:, 2, 2] = 1 - 2 * (x*x + y*y) return RPoint Cloud Data (pcd) processing: def create_from_pcd(self, pcd: BasicPointCloud, spatial_lr_scale: float): self.spatial_lr_scale = spatial_lr_scale fused_point_cloud = torch.tensor(np.asarray(pcd.points)).float().cuda() fused_color = RGB2SH(torch.tensor(np.asarray(pcd.colors)).float().cuda()) features = torch.zeros((fused_color.shape[0], 3, (self.max_sh_degree + 1) ** 2)).float().cuda() features[:, :3, 0 ] = fused_color features[:, 3:, 1:] = 0.0 print(&quot;Number of points at initialisation : &quot;, fused_point_cloud.shape[0]) dist2 = torch.clamp_min(distCUDA2(torch.from_numpy(np.asarray(pcd.points)).float().cuda()), 0.0000001) scales = torch.log(torch.sqrt(dist2))[...,None].repeat(1, 3) rots = torch.zeros((fused_point_cloud.shape[0], 4), device=&quot;cuda&quot;) rots[:, 0] = 1 opacities = inverse_sigmoid(0.1 * torch.ones((fused_point_cloud.shape[0], 1), dtype=torch.float, device=&quot;cuda&quot;)) self._xyz = nn.Parameter(fused_point_cloud.requires_grad_(True)) self._features_dc = nn.Parameter(features[:,:,0:1].transpose(1, 2).contiguous().requires_grad_(True)) self._features_rest = nn.Parameter(features[:,:,1:].transpose(1, 2).contiguous().requires_grad_(True)) self._scaling = nn.Parameter(scales.requires_grad_(True)) self._rotation = nn.Parameter(rots.requires_grad_(True)) self._opacity = nn.Parameter(opacities.requires_grad_(True)) self.max_radii2D = torch.zeros((self.get_xyz.shape[0]), device=&quot;cuda&quot;) def densify_and_prune(self, max_grad, min_opacity, extent, max_screen_size): grads = self.xyz_gradient_accum / self.denom # calculate the gradients of estimated density grads[grads.isnan()] = 0.0 self.densify_and_clone(grads, max_grad, extent) # density and clone for under reconstrution areas self.densify_and_split(grads, max_grad, extent) # density and split for over reconstrution areas prune_mask = (self.get_opacity &amp;lt; min_opacity).squeeze() # mask points with opacity smaller than threshold if max_screen_size: big_points_vs = self.max_radii2D &amp;gt; max_screen_size # mark points with radius greater than threshold big_points_ws = self.get_scaling.max(dim=1).values &amp;gt; 0.1 * extent # mark points with scales greater than threshold prune_mask = torch.logical_or(torch.logical_or(prune_mask, big_points_vs), big_points_ws) # get the final prune mask self.prune_points(prune_mask) # prune parameters torch.cuda.empty_cache() # clear the GPU cache def densification_postfix(self, new_xyz, new_features_dc, new_features_rest, new_opacities, new_scaling, new_rotation): d = {&quot;xyz&quot;: new_xyz, &quot;f_dc&quot;: new_features_dc, &quot;f_rest&quot;: new_features_rest, &quot;opacity&quot;: new_opacities, &quot;scaling&quot; : new_scaling, &quot;rotation&quot; : new_rotation} optimizable_tensors = self.cat_tensors_to_optimizer(d) self._xyz = optimizable_tensors[&quot;xyz&quot;] self._features_dc = optimizable_tensors[&quot;f_dc&quot;] self._features_rest = optimizable_tensors[&quot;f_rest&quot;] self._opacity = optimizable_tensors[&quot;opacity&quot;] self._scaling = optimizable_tensors[&quot;scaling&quot;] self._rotation = optimizable_tensors[&quot;rotation&quot;] self.xyz_gradient_accum = torch.zeros((self.get_xyz.shape[0], 1), device=&quot;cuda&quot;) self.denom = torch.zeros((self.get_xyz.shape[0], 1), device=&quot;cuda&quot;) self.max_radii2D = torch.zeros((self.get_xyz.shape[0]), device=&quot;cuda&quot;)作者：lingjivoo，github主页：传送门" }, { "title": "Collection of Oral Expressions", "url": "/posts/Collection-of-Oral-Expressions/", "categories": "Study", "tags": "Oral", "date": "2023-12-19 18:02:00 +0800", "snippet": "Collection of great vocabulary for paper writing 1 Tons of image pixels You can have tons of image pixels. 2 there is a good pick for this 3 Gaussian spread 4 here we go 5 it’s going to be 6 basiclly means 7 that’s generally not going to be the case 8 put them through the softmax 9 somebody figured out a way 10 this is a huge speed up 11 ultimately what I am trying to get you guys to understand here is that there is … 12 kind of it kind of sounds like 13 If sb would have done sth If they would have just stopped here, this paper would have just taken forever it would have produced something that is sure it’s high quality 14 shuffled away No one cares about it and it gets shuffled away and forgotten about. 15 on streamin or into regular operation, especially as part of a system, assembly line, or the like: tons of paper on stream. 16 you’ve got There are 1996 papers -&amp;gt; you’ve got some 1996 papers 17 basically around they are based on the idea of -&amp;gt; they are basically around the idea of 18 they are looking at They focus on -&amp;gt; they are looking at xxx 19 It is packed too many people heare 20 up there / down there I live down there 21 what brought sb + place What brought you to Paris, What brought you here? 22 Every since Every since I got here, every since I was a child. 23 Get sb’s way You always get your way. I’m used to getting my way too. 24 mood swings a change of mood. 25 give me whiplash whiplash: any reaction to a sudden changeshe really gave me a whiplash 26 It’d be better if it used to make a suggestion about what you think should be done/happen.she really gave me a whiplash 27 Not that not that I did not wanna be 28 What does that mean 29 Let’s say You can say this when considering what might happen if sth occursLet’s say you have a million dollars, what would you do with it? 30 For the sake of / for sb’s sake/ for argument’s sake in order to help sb or sth 31 probably not 32 Let’s instead pretend that Let’s instead pretend that these 3D gaussians are these little ellipsoids. 33 I’m + adj + of a person I’m too stressful of a person. 34 get overwhelmed do not know what to doit is really easy to get overwhelmed 35 grill to ask sb a lot of questions about their ideas, actions often in an unpleasant way.start grilling me 36 wait till after let’s wait till after Christmas 37 walk on eggshell To be very careful about what you say or do to someone because they’re easily upset or offended 38 spare one’s feeling To be careful not to do or say anything that might upset sb 38 sugar-coating sth To do sth that makes an unpleasant situation seems less unpleasant. 39 **the whole point of ** the whole point of these model is they’re . 40 be putty in his hand be controlled or affected by somebody. 作者：lingjivoo，github主页：传送门" }, { "title": "Collection of great vocabulary for paper writing", "url": "/posts/Collection-of-Writing-Vocabulary/", "categories": "Study", "tags": "writing", "date": "2023-12-12 18:40:00 +0800", "snippet": "Collection of great vocabulary for paper writing 1 on the fly dynamically, while in motion or progress example: During training, the two components incorporate the estimated depth to produce supervisory signals on the fly. (copy from StructDepth) 2 data starvation/ supervision starvationre 3 hinting at a possibility fora hint to the possibility, provide a potential for example: In contrast, recent large language models exhibit a wide range of capabilities, hinting at a possibility for similarly versatile models in computer vision. (copy from 4M) 4 out of box immediate usability (typically an electronic device or a piece of software), unusually good (the novel is nothing out of the box). example: 4M leads to models that exhibit several key capabilities: (1) they can perform a diverse set of vision tasks out of the box. (copy from 4M) 5 remarkable flexibilitycan be used for describing controllability or editing, example: enabling a wide variety of expressive multimodal editing capabilities with remarkable flexibility. (copy from 4M) 6 The field has seen a shift towardsfor the first paragraph in Introduction, the beginning of a storyline. example: In recent years, the field of natural language processing (NLP) has seen a shift toward training large language models (LLMs) that are inherently capable of performing a wide range of tasks without requiring extensive task-specific adaptations [12, 25]. (copy from 4M) 7 there remains a need toTranslation in Introduction. Translation from previous works to problems/needs or our work. example: While these models have demonstrated remarkable success in NLP, there remains a need to develop similarly versatile and scalable models for vision.. (copy from 4M) 8 delve into to try hard to find out more information about something. In this report, we delve into the performance of LLMs within the context of scientific discovery/research, focusing on GPT-4 (copy from Imapct of LLM on Scientific Discovery). 9 Broadly speakingwithout regard to specific details or exceptions example: Broadly speaking, we evaluate GPT-4’s knowledge base, scientific understanding, scientific numerical calculation abilities, and various scientific prediction capabilities (copy from Imapct of LLM on Scientific Discovery). 10 transform the way examples: i)Transform The Way You Work, and ii) LLMs are capable of transforming the way we generate and process information (copy from Imapct of LLM on Scientific Discovery). 11 transform the way examples: i)Transform The Way You Work, and ii) LLMs are capable of transforming the way we generate and process information (copy from Imapct of LLM on Scientific Discovery). 12 extraordinary capabilities example: Because of its extraordinary capabilities in general AI tasks, GPT-4 is also garnering significant attention in the scientific community. 13 central focus example: Our aim is to provide a broad overview of LLMs’ performance and their potential applicability in these specific scientific fields, with GPT-4, the state-of-the-art LLM, as our central focus. 14 and beyond example: These strive to uncover the fundamental principles and laws governing the universe, spanning from the smallest subatomic particles to the largest galaxies and beyond. 15 a wide array of example: Natural science is an incredibly diverse field, encompassing a wide array of disciplines, including both physical sciences, which focus on non-living systems, and life sciences, which investigate living organisms. 16 overlaps witha part of the first thing occupies the same area as a part of the other thing. example: It is important to note that these areas are not mutually exclusive; for example, drug discovery substantially overlaps with biology. 17 by whichBy which = How or whereby or “through which” example: Drug discovery is the process by which new candidate medications are identified and developed to treat or prevent specific diseases and medical conditions. 18 on most frontsof most aspects example: outperform these methods on most fronts (copy from 3D Gaussian splatting). 18 follow-up methods example: The success of NeRF has resulted in an explosion of follow-up methods that address quality and speed, often by introducing regularization strategies. (copy from 3D Gaussian splatting). 19 equal example: We are able to equal or in some cases surpass this quality while providing fast training and real-time rendering. (copy from 3D Gaussian splatting). 20 pave the way for the application of xx in example: 21 charting future research paths a multitude of studies have surfaced with the aim of charting future research paths, which have varied from identifying emerging trends to highlighting areas poised for swift progress. 22 despite the curse of There is problem ……High-quality samples generated with score-based reverse diffusion algorithms provide evidence that deep neural networks (DNN) trained for denoising can learn high-dimensional densities, despite the curse of dimensionality. 23 ever-more Deep neural networks (DNNs) have demonstrated ever-more impressive capabilities for learning and sampling from high-dimensional image densities. 作者：lingjivoo，github主页：传送门" }, { "title": "First Blog", "url": "/posts/First-Blog/", "categories": "Essay", "tags": "feelings, diary", "date": "2023-12-08 14:42:00 +0800", "snippet": "随笔第一篇博客, 目的记录下以后的科研生活。之前踩了很多坑确没有记录下来，每次再回想时候已经模糊了。所有有了这个博客，来记录下成长路上的点点滴滴。加油！ 忙去了 :)作者：lingjivoo，github主页：传送门" } ]
